After creating cluster:

check the working directory:
> pwd  # this shows the current working directory

Creating an new directory:
> sudo mkdir -p /home/bidhan # this will create a new directory inside the home directory

getting into the directory:
> cd /home/bidhan # this will take us inside the bidhan directory

importing files to the cluster:
> wget https://example.com/large_dataset.zip

> curl -O https://example.com/large_dataset.zip

for password protected locations:
wget --user=username --password=password --recursive --no-parent -P /home/bidhan_pokhrel_dubai_gmail_com/folder https://example.com/data/


with zip:
wget https://example.com/path/to/archive.zip -O - | unzip -d /home/bidhan_pokhrel_dubai_gmail_com/

curl -L https://example.com/path/to/archive.zip | unzip -d /home/bidhan_pokhrel_dubai_gmail_com/


For importing the dataset from google bucket:
> gsutil ls gs://bidhan/   # this will list all the files inside the bucket
> gsutil cp gs://bidhan/mapper.py /home/bidhan_pokhrel_dubai_gmail_com/



UPLOADING THE CLUSTER FILE TO GOOGLE BUCKET:

gsutil cp health_dataset.csv gs://bidhan

checking the file type:
> file <filename>

checking the file permissions of the file:
> ls -l <filename>


what if zip file?
> sudo apt-get update
> sudo apt-get install unzip -y
> unzip health_dataset.zip # to unzip the file.
> zip health_dataset.zip health_dataset.csv # to zip the existing files.

Important Options:
-r : Recursively include directories
-9 : Maximum compression
-q : Quiet mode (suppresses output)
-e : Encrypt with password



